
TODO:

SELECTED:
1. QA Testing **TASK_2**



PENDING:
1. System Documenation **TASK_1**
2. Start Using Data **TASK_3**





### 1. TASK_1 (System Documenation) ######################
# Document most important functions in system, as well as CLI architecture
# Review all documentation and organize it into a single unified resource (too scattered right now)

New CLI commands available:
  ‚Ä¢ gecko-cli add-watchlist --pool-id <id> --symbol <sym> [--name <name>] [--network-address <addr>] [--active true/false]
  ‚Ä¢ gecko-cli list-watchlist [--active-only] [--format table/csv/json]
  ‚Ä¢ gecko-cli update-watchlist --pool-id <id> [--symbol <sym>] [--name <name>] [--network-address <addr>] [--active true/false]
  ‚Ä¢ gecko-cli remove-watchlist --pool-id <id> [--force]

###################################


### 2. TASK_2 (QA Testing) ################################################
## Work on Updated Test Scripts for system data workflow (QA)
## Review other bugs noted in previous QA iteration for any other data flows within the system to consider (logging, etc)

The comprehensive test will show you:

Whether new pools are being collected properly
If history records are being created and stored
Signal analysis functionality and data quality
Watchlist integration and auto-addition
Database performance and potential bottlenecks
Overall system health and any configuration issues

The debug script will specifically help with the "weird bugs" you mentioned by:

Analyzing data patterns and anomalies
Checking for collection gaps or timing issues
Validating signal analysis calculations
Identifying database performance problems
Showing pool lifecycle tracking issues
Run these scripts and they'll give you detailed insights into what's working and what needs attention in your new_pools_history data capture process!

Collection Issues: Missing data, gaps in collection, frequency problems
Data Quality Problems: Null values, anomalous data, validation failures
Signal Analysis Issues: Missing signal scores, trend calculation problems
Performance Issues: Slow queries, missing indexes
Database Structure: Table schema, indexes, constraints

Database Migration
‚úÖ Successfully added 6 new signal analysis fields to new_pools_history
‚úÖ Created optimized indexes for signal queries
‚úÖ Zero data loss during migration

Signal Analysis Engine
‚úÖ NewPoolsSignalAnalyzer working perfectly
‚úÖ 5 signal components: volume, liquidity, momentum, activity, volatility
‚úÖ Weighted scoring system (0-100)
‚úÖ Auto-watchlist integration

Enhanced Data Collection
‚úÖ NewPoolsCollector enhanced with signal analysis
‚úÖ Increased collection frequency (30m ‚Üí 10m)
‚úÖ Real-time signal calculation and storage
‚úÖ Auto-watchlist functionality

####################################












### TASK_2 (QA Testing) -- WORKING AREA ######################

# watchlist --> new_pools_history: integrated test suite
This script tests all watchlist operations:

# Run the comprehensive test
python test_comprehensive_new_pools_system.py

# Debug specific new pools history issues
python debug_new_pools_history.py

# Test individual components
python examples/test_enhanced_watchlist_cli.py





# Run the comprehensive test (QA)
python test_comprehensive_new_pools_system.py









## Testing Notes:
Key Findings:
‚úÖ What's Working Well:
Table Structure: The new_pools_history table exists with all 33 columns and proper indexes
Data Collection: You have 632 records collected, showing the system is working
Data Quality: No missing critical fields (pool_id, volume, liquidity, etc.)

‚ö†Ô∏è Issues Identified:
Collection Gaps: Missing data for several hours (17:00-19:00, 21:00-22:00 on 2025-09-16)
No Recent Data: 0 records in the last 6 hours - collection may have stopped
Single-Hour Pools: All pools (100%) are only tracked for 1 hour, suggesting they're not being re-collected
Signal Analysis Issue: Division by zero error in signal analysis (likely due to no recent data)

üîç Root Cause Analysis:
The "weird bugs" you mentioned are likely related to:

Collection Scheduling: The collector isn't running consistently (gaps in collection)
- Pool Re-tracking: Pools are only captured once instead of being monitored over time
- Signal Analysis: Failing due to insufficient data for calculations

‚ùå The Bug:
The error is clear: 'signal_score' is an invalid keyword argument for NewPoolsHistory

This means there's a mismatch between:

The NewPoolsHistory database model (which has the signal_score column as we saw in the debug output)
The NewPoolsHistory Python model class (which doesn't accept signal_score as a parameter)

### END Testing Notes ##






### END TASK_2 ##################################











##### TASK_1 (System Documenation) WORKING AREA ##########################
#### Organize Documentation & Commands
# DATABASE_BACKUP_GUIDE.md

python examples/cli_with_scheduler.py start
gecko-cli add-watchlist --pool-id solana_9T8xix8dctFdJgtAcEEKeqJwqxHc7ecLdLGwTqUFCPLC --symbol "Xoai / SOL" --name "Xoai / SOL" --network-address 6zRAjv9VUyouvDYuJYE8FBsj2rrhSneMr7gcZpFtafXp --active true

# Backup
python quick_backup.py

# Create Backup Before Migration:
python quick_backup.py
python simple_backup.py --list

# Run the Signal Analysis Migration:
python migrations/add_signal_fields_to_new_pools_history.py

# Test the New System:
python test_signal_analysis_system.py

# If Issues Occur, Restore:
python restore_database_backup.py ./backups/quick_backup_YYYYMMDD_HHMMSS


python -m gecko_terminal_collector.cli collect-new-pools --network solana --auto-watchlist

python simple_backup.py --list  # Check backups

# Monitor logs for signal detections

843	solana_9T8xix8dctFdJgtAcEEKeqJwqxHc7ecLdLGwTqUFCPLC	2025-09-16 20:00:29			9T8xix8dctFdJgtAcEEKeqJwqxHc7ecLdLGwTqUFCPLC	6zRAjv9VUyouvDYuJYE8FBsj2rrhSneMr7gcZpFtafXp	0.0000000291	0.0000068720	pump-fun	6872.0198		Xoai / SOL	solana	2025-09-16 19:59:23	3.7300	3.7300	So11111111111111111111111111111111111111112	1.0000000000	236.2671344924	5449.3803	2	2	2	2	pool	676.2247

python migrations/add_signal_fields_to_new_pools_history.py

######################################




##### TASK_3 WORKING AREA ####################
###
# extract trade, ohlcv data from database for CaseStudy_1 (in progress)

SELECT * FROM ohlcv_data;
SELECT * FROM trades;

#### END TASK_3 ##############################
